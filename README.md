# salt-identification

### TGS Salt Identification Challenge

The goal of this competition was to identify segments of seismic images which 
contain salt deposits. The data includes (1) the seismic images (2) masks 
showing the portions of the training images containing salt, and (3) the depths 
at which each image was taken. For an in-depth explanation of the contest, see 
the official 
[Kaggle page](https://www.kaggle.com/c/tgs-salt-identification-challenge).

### Final results

Not revealed yet! The contest ends **October 19, 2018 at 11:59 PM UTC**.

### What's in this repository?

The following files contain all of the code used to make my final predictions:

* `main.py` reads in the data, performs preprocessing and modeling, and then 
generates the predictions.

* `models.py` fully implements the models I built for this competition.

* `utilities.py` contains miscellaneous functions throughout the project.

* `lovasz.py` contains functions needed to implement Lovasz loss, which is used 
during the training process as an approximate substitute for the IOU metric.

Lastly, the subdirectories are:

* `data/` is where the training and testing data goes. The image data is not in 
the repository. To run this project, you need to manually download it from 
Kaggle and extract it to this folder. See `data/placeholder.txt` for exact 
details. 

* `output/` is created when `main.py` is run for the first time. All files 
generated by the project will go here, including saved models and predictions.

* `papers/` contains several papers I used as references for my model 
architectures and techniques. All are freely available on the internet.

### Ideas for Improvement

* Change the kernel initializer to `'he_normal'`, which is what the original
U-Net paper recommends

* Tune the dropout ratio

* Remove the dropout in the last layer

* An alternative model which resizes the input from 101x101 to 128x128

* Stratify by depth in addition to coverage

* 5-fold CV instead of 1-fold CV

* Ensemble methods with more models (e.g., pre-trained models) 
(`https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/64645`)
(`https://www.kaggle.com/alexanderliao/u-net-bn-aug-strat-focal-loss`)
(`https://www.kaggle.com/meaninglesslives/unet-resnet34-in-keras`)

* Conditional random field 
(`https://github.com/sadeepj/crfasrnn_keras`)
(`https://www.kaggle.com/meaninglesslives/apply-crf`)
(`https://www.kaggle.com/meaninglesslives/apply-crf-unet-resnet`)

* Include depth in model

* Vertical flipping in addition to horizontal flipping

* Image augmentation with deformations and intensity

* Tune contraction, middle, and expansion blocks separately

* Try dropping the messed-up mask 
(`https://www.kaggle.com/pestipeti/fake-incorrect-training-masks`)

* Check expansion block ("replace conv2D with 2 basic resnet blocks in each 
level of U-net")
(`https://www.kaggle.com/divrikwicky/u-net-with-simple-resnet-blocks-forked`)

* Read through this: 
(`https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/65226`)

* Make sure the best model is used to make predictions; try loading the saved 
model, retraining on all data, or look at 5-fold CV point above

* Look for ideas on GitHub

* Optimizer momentum -> 0.90; dropout -> 0.2, neurons -> double, 
batch size -> smaller (4?) 

